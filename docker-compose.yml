version: '3' 
services:

  namenode:
    container_name: namenode
    hostname: namenode
    build: ./data/namenode
    image: namenode
    volumes:
      - ./data/namenode:/hadoop/dfs/name
      - ./data/namenode/install.properties:/opt/ranger-hdfs-plugin/install.properties
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./data/hive/hadoop-hive.env
    ports:
      - "50070:50070"
      - "8020:8020"
    deploy:
      resources:
        limits:
          memory: 500m
  
  datanode:
    container_name: datanode
    hostname: datanode
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - ./data/datanode:/hadoop/dfs/data
    env_file:
      - ./data/hive/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"
    deploy:
      resources:
        limits:
          memory: 500m
  
  hive-server:
    build: ./data/hive
    image: hive-server
    env_file:
      - ./data/hive/hadoop-hive.env
    volumes:
      - ./data/hive/atlas-application.properties:/opt/hive/conf/atlas-application.properties
      - ./data/hive/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./data/hive/hive-env.sh:/opt/hive/conf/hive-env.sh
      - ./data/hive/atlas-hive-hook:/opt/atlas-hive-hook
      - ./data/hive/install.properties:/opt/ranger-hive-plugin/install.properties
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
    deploy:
      resources:
        limits:
          memory: 500m
  
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./data/hive/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    deploy:
      resources:
        limits:
          memory: 500m
  
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    deploy:
      resources:
        limits:
          memory: 500m

  hue:
    image: fjardim/hue
    hostname: hue
    container_name: hue
    dns: 8.8.8.8
    ports:
      - "8888:8888"
    volumes:
      - ./data/hue/hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      - database_hue
    deploy:
      resources:
        limits:
          memory: 500m

  ranger-admin:
    image: kadensungbincho/ranger-admin:2.1.0
    container_name: ranger-admin
    hostname: ranger
    depends_on:
      - database_ranger
    volumes:
      - ./data/ranger/admin/bootstrap.sh:/opt/ranger_admin/bootstrap.sh
      - ./data/ranger/admin/install.properties:/opt/ranger_admin/install.properties
    command: ["./bootstrap.sh"]
    ports:
      - "6080:6080"
    restart: always

  ranger-usersync:
    image: kadensungbincho/ranger-usersync:2.1.0
    container_name: ranger-usersync
    hostname: usersync
    depends_on:
      - ranger-admin
    volumes:
      - ./data/ranger/usersync/bootstrap.sh:/opt/ranger_usersync/bootstrap.sh
      - ./data/ranger/usersync/install.properties:/opt/ranger_usersync/install.properties
    command: ["./bootstrap.sh"]
    restart: always

  database_ranger:
    image: mysql:5.7
    hostname: database_ranger
    volumes:
      - ./data/ranger/mysql:/var/lib/mysql
    restart: always
    ports:
      - "33062:3306"
    container_name: ranger-db
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: ranger
      MYSQL_USER: ranger
      MYSQL_PASSWORD: ranger


  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
    container_name: ranger-es
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "ELASTIC_PASSWORD=elasticsearch"
    volumes:
      - ./data/ranger/es:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
  
  database_hue:
    image: fjardim/mysql
    container_name: database
    hostname: database
    ports:
        - "33061:3306"
    deploy:
      resources:
        limits:
          memory: 500m
    command: mysqld --innodb-flush-method=O_DSYNC --innodb-use-native-aio=OFF --init-file /data/application/init.sql
    volumes:
        - ./data/mysql/data:/var/lib/mysql
        - ./data/mysql/init.sql:/data/application/init.sql
    environment:
        MYSQL_ROOT_USER: root
        MYSQL_ROOT_PASSWORD: secret
        MYSQL_DATABASE: hue
        MYSQL_USER: root
        MYSQL_PASSWORD: secret

  zookeeper:
    image: fjardim/zookeeper
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - ./data/zookeeper:/opt/zookeeper-3.4.6/data
    deploy:
      resources:
        limits:
          memory: 500m

  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "create_events:1:1,delete_events:1:1,ATLAS_HOOK:1:1"
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    depends_on:
      - zookeeper 
    deploy:
      resources:
        limits:
          memory: 500m

  presto-coordinator:
    image: fjardim/prestodb
    container_name: presto
    hostname: presto
    ports:
      - "8080:8080"
    depends_on:
      - hive-server  
    deploy:
      resources:
        limits:
          memory: 500m

  hbase-master:
    image: fjardim/hbase-master
    container_name: hbase-master
    hostname: hbase-master
    env_file:
      - ./data/hbase/hbase-standalone.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181"
    ports:
      - 16010:16010
    depends_on:
      - namenode
    deploy:
      resources:
        limits:
          memory: 500m
  
  mongo:
    image: fjardim/mongo
    container_name: mongo
    hostname: mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
    ports:
      - 27017:27017
    volumes:
      - ./data/mongo:/data
    deploy:
      resources:
        limits:
          memory: 500m
 
  mongo-express:
    image: fjardim/mongo-express
    container_name: mongo_express
    hostname: mongo_express
    restart: always
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: root
      ME_CONFIG_MONGODB_SERVER: mongo
    deploy:
      resources:
        limits:
          memory: 200m
 
  kafkamanager:
    image: fjardim/kafkamanager
    container_name: kafkamanager
    hostname: kafkamanager
    environment: 
      ZK_HOSTS: zookeeper:2181
    ports:
      - 9000:9000
    depends_on:
      - kafka
    deploy:
      resources:
        limits:
          memory: 200m
 
  metabase:
    image: fjardim/metabase
    container_name: metabase
    hostname: metabase
    volumes:
      - ./data/metabase/data:/metabase-data
    environment:
      MB_DB_FILE: "/metabase-data/metabase.db"
    ports:
      - 3000:3000
    deploy:
      resources:
        limits:
          memory: 500m
 
  nifi:
    image: fjardim/nifi
    container_name: nifi
    hostname: nifi
    volumes:
      - ./data/nifi:/opt/nifi/nifi-current/flowfile_repository
      - ./data/util:/util
    environment:
      NIFI_WEB_HTTP_PORT: "9090"
    ports:
      - "9090:9090"
      - "8443:8443"
    deploy:
      resources:
        limits:
          memory: 500m

  jupyter-spark:
    image: fjardim/jupyter-spark
    hostname: jupyter-spark
    container_name: jupyter-spark
    command: notebook
    env_file:
      - ./data/jupyter/jupyter.env
    ports:
      - 8889:8889
      - 4040:4040
      - 4041:4041
      - 4042:4042
      - 4043:4043
    volumes:
       - ./data/notebooks:/mnt/notebooks/
    environment:
       SPARK_MASTER: local[*]
       JUPYTER_PORT: 8889
    deploy:
      resources:
        limits:
          memory: 1g

  solr:
    image: solr:latest
    container_name: solr
    ports:
      - "8983:8983"
    deploy:
      resources:
        limits:
          memory: 200m

  atlas-server:
    hostname: atlas-server
    container_name: atlas-server
    build: ./data/atlas
    image: wbaa/rokku-dev-apache-atlas
    volumes:
      - ./data/atlas/resources/1000-Hadoop:/opt/atlas/models/1000-Hadoop
    ports:
      - "21000:21000"
    depends_on:
      - "zookeeper"
      - "kafka" 