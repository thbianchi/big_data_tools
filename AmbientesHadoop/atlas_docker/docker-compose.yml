version: "2"
services:

  atlas-server:
    image: leandroaa/atlas
    volumes:
      - ./atlas/resources/1000-Hadoop:/opt/atlas/models/1000-Hadoop
    ports:
      - "21000:21000"
    depends_on:
      - "zookeeper"
      - "kafka" 

  zookeeper:
    image: wurstmeister/zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"  

  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "create_events:1:1,delete_events:1:1,ATLAS_HOOK:1:1"
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    depends_on:
      - zookeeper  
  
  spark:
    build: ./spark
    command: /bin/bash
    tty: true
    volumes:
      - ./spark/atlas-application.properties:/usr/local/spark/conf/atlas-application.properties
      - ./spark/users-credentials.properties:/usr/local/spark/users-credentials.properties
      - ./spark/spark-atlas-connector-assembly-0.1.0-SNAPSHOT.jar:/usr/local/spark/jars/spark-atlas-connector-assembly-0.1.0-SNAPSHOT.jar
      - ./spark/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
      - ./spark/teste.py:/tmp/teste.py

  namenode:
    container_name: namenode
    hostname: namenode
    build: ./namenode
    image: namenode
    volumes:
      - ./namenode:/hadoop/dfs/name
      - ./namenode/install.properties:/opt/ranger-hdfs-plugin/install.properties
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hive/hadoop-hive.env
    ports:
      - "50070:50070"
      - "8020:8020"

  datanode:
    container_name: datanode
    hostname: datanode
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - ./datanode:/hadoop/dfs/data
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"
  
  hive-server:
    build: ./hive
    image: hive-server
    env_file:
      - ./hive/hadoop-hive.env
    volumes:
      - ./hive/atlas-application.properties:/opt/hive/conf/atlas-application.properties
      - ./hive/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./hive/hive-env.sh:/opt/hive/conf/hive-env.sh
      - ./hive/atlas-hive-hook:/opt/atlas-hive-hook
      - ./hive/install.properties:/opt/ranger-hive-plugin/install.properties
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hive/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    ports:
      - "5432:5432"

  # hue:
  #   image: fjardim/hue
  #   hostname: hue
  #   container_name: hue
  #   dns: 8.8.8.8
  #   ports:
  #     - "8888:8888"
  #   volumes:
  #     - ./hue/hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
  #   depends_on:
  #     - hue-db
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 500m

  # hue-db:
  #   image: fjardim/mysql
  #   container_name: hue-db
  #   hostname: hue-db
  #   ports:
  #       - "33061:3306"
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 500m
  #   command: mysqld --innodb-flush-method=O_DSYNC --innodb-use-native-aio=OFF --init-file /data/application/init.sql
  #   volumes:
  #       - ./hue/mysql/data:/var/lib/mysql
  #       - ./hue/mysql/init.sql:/data/application/init.sql
  #   environment:
  #       MYSQL_ROOT_USER: root
  #       MYSQL_ROOT_PASSWORD: secret
  #       MYSQL_DATABASE: hue
  #       MYSQL_USER: root
  #       MYSQL_PASSWORD: secret
